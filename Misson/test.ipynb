{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460b760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2d0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "root = './data'\n",
    "mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95680b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6558, -0.9865, -0.3268,  ...,  1.3842, -0.4537,  2.0292],\n",
       "        [-0.4716,  0.4212,  0.8715,  ...,  0.6578,  0.1918, -0.0359],\n",
       "        [ 0.8237, -0.7472, -0.8979,  ..., -0.2953,  0.3836,  0.6029],\n",
       "        ...,\n",
       "        [-0.8371,  0.8613,  0.5890,  ...,  0.3800,  0.6788, -0.5509],\n",
       "        [-0.5659, -0.3064, -0.8841,  ..., -0.2912,  0.2062, -1.0937],\n",
       "        [ 0.6580,  0.0699,  1.1987,  ...,  1.0337, -0.7570, -0.0434]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "linear = torch.nn.Linear(784, 10, bias = True).to(device)\n",
    "torch.nn.init.normal_(linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be07a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c986fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)        \n",
    "        imgs = imgs.view(-1, 28*28)\n",
    "\n",
    "        outputs = linear(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax.to(device)).float().mean()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {: .4f}, Accuracy: {: .2f}%'.format(\n",
    "                epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item()* 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5f4c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for 10000 images:  89.31%\n"
     ]
    }
   ],
   "source": [
    "linear.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1, 28 * 28)\n",
    "\n",
    "        outputs = linear(imgs)\n",
    "\n",
    "        _, argmax = torch.max(outputs, 1) \n",
    "        total += imgs.size(0)\n",
    "        correct += (labels == argmax).sum().item()\n",
    "    \n",
    "    print('Test accuracy for {} images: {: .2f}%'.format(total, correct / total * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f8929016d30f12a89eab5b5e02a6c1410fc73da4b23b89b4eb7a3bc58137fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
