{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce0e0c5e",
   "metadata": {},
   "source": [
    "ğŸ“ŒQ1. ê°€ì¥ ë¨¼ì € í•™ìŠµ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. MNIST ë°ì´í„°ì…‹ì„ ì§ì ‘ Loadí•´ ë´…ì‹œë‹¤. ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  DataLoaderë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”.\n",
    "\n",
    "- DataLoaderë¥¼ ì´ìš©í•´ MNIST ë°ì´í„°ì…‹ì„ ë¡œë“œí•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "root = './data'\n",
    "mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ca8e81a",
   "metadata": {},
   "source": [
    "ğŸ“ŒQ2.ë°ì´í„°ê°€ ì¤€ë¹„ê°€ ë˜ì—ˆë‹¤ë©´, ì´ì œ ê·¸ ë°ì´í„°ë¥¼ í•™ìŠµí•  ëª¨ë¸ì„ êµ¬í˜„í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ê·¸í›„ ëª¨ë¸ ì•ˆì˜ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”ì‹œì¼œë³´ì„¸ìš”. ì…ë ¥ ë°ì´í„° í˜•íƒœì— ë§ë„ë¡ linearí•œ ëª¨ë¸ì„ êµ¬ì„±í•´ë³´ì„¸ìš”.\n",
    "\n",
    "- MNIST ì…ë ¥ì˜ í¬ê¸°ëŠ” 28x28ì…ë‹ˆë‹¤.\n",
    "\n",
    "- ì—¬ê¸°ì„œ êµ¬í˜„í•˜ëŠ” linear ëª¨ë¸ì€ ì…ë ¥ì´ 1ì°¨ì›ì´ê¸° ë•Œë¬¸ì— ì…ë ¥ ì°¨ì›ì„ ë§ì¶°ë³´ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6558, -0.9865, -0.3268,  ...,  1.3842, -0.4537,  2.0292],\n",
       "        [-0.4716,  0.4212,  0.8715,  ...,  0.6578,  0.1918, -0.0359],\n",
       "        [ 0.8237, -0.7472, -0.8979,  ..., -0.2953,  0.3836,  0.6029],\n",
       "        ...,\n",
       "        [-0.8371,  0.8613,  0.5890,  ...,  0.3800,  0.6788, -0.5509],\n",
       "        [-0.5659, -0.3064, -0.8841,  ..., -0.2912,  0.2062, -1.0937],\n",
       "        [ 0.6580,  0.0699,  1.1987,  ...,  1.0337, -0.7570, -0.0434]],\n",
       "       requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "linear = torch.nn.Linear(784, 10, bias = True).to(device)\n",
    "torch.nn.init.normal_(linear.weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d451012a",
   "metadata": {},
   "source": [
    "ğŸ“ŒQ3. ìœ„ì—ì„œ êµ¬í˜„í•œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” loss í•¨ìˆ˜ì™€ opitmizerê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "ì•„ë˜ ì œì‹œëœ loss í•¨ìˆ˜ì™€ optimizerë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”. Loss í•¨ìˆ˜ì™€ optimizerëŠ” ëª¨ë¸ ì•ˆ\n",
    "ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸ í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "- ì˜µí‹°ë§ˆì´ì €ëŠ” SGD, LossëŠ” Cross Entropy Lossë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f92e6fc6",
   "metadata": {},
   "source": [
    "ğŸ“ŒQ4. 3ë²ˆ ë¬¸ì œê¹Œì§€ í•´ê²°í•˜ì…¨ë‹¤ë©´, ì´ì œ í•™ìŠµì„ ìœ„í•œ ì¤€ë¹„ëŠ” ê±°ì˜ ëë‚¬ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ìœ„ êµ¬í˜„ í•¨ìˆ˜ë“¤ì„ ì´ìš©í•´ í•™ìŠµ Loopë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”.\n",
    "\n",
    "- ìœ„ì—ì„œ êµ¬í˜„í•œ ëª¨ë¸, optimzer, loss fn ë“±ì„ ì´ìš©í•´ í•™ìŠµì„ êµ¬í˜„í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec904fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)        \n",
    "        imgs = imgs.view(-1, 28*28)\n",
    "\n",
    "        outputs = linear(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax.to(device)).float().mean()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {: .4f}, Accuracy: {: .2f}%'.format(\n",
    "                epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item()* 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a4cb30a",
   "metadata": {},
   "source": [
    "ğŸ“ŒQ5. í•™ìŠµì´ ì™„ë£Œë˜ë©´, ëª¨ë¸ì´ ì˜ ë™ì‘í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë°ì´í„°ë¡œë“œ íŒŒíŠ¸ì—ì„œ\n",
    "ì¤€ë¹„í–ˆë˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•´ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ë´…ì‹œë‹¤. ì•„ë˜ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì™„ì„±í•´ë³´\n",
    "ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1, 28 * 28)\n",
    "\n",
    "        outputs = linear(imgs)\n",
    "\n",
    "        _, argmax = torch.max(outputs, 1) \n",
    "        total += imgs.size(0)\n",
    "        correct += (labels == argmax).sum().item()\n",
    "    \n",
    "    print('Test accuracy for {} images: {: .2f}%'.format(total, correct / total * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f8929016d30f12a89eab5b5e02a6c1410fc73da4b23b89b4eb7a3bc58137fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
