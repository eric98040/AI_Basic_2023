{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce0e0c5e",
   "metadata": {},
   "source": [
    "📌Q1. 가장 먼저 학습 데이터를 준비해보도록 하겠습니다. MNIST 데이터셋을 직접 Load해 봅시다. 데이터셋을 로드하고 DataLoader를 구현해보세요.\n",
    "\n",
    "- DataLoader를 이용해 MNIST 데이터셋을 로드해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "root = './data'\n",
    "mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = batch_size, shuffle = False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ca8e81a",
   "metadata": {},
   "source": [
    "📌Q2.데이터가 준비가 되었다면, 이제 그 데이터를 학습할 모델을 구현할 차례입니다. 그후 모델 안의 가중치를 초기화시켜보세요. 입력 데이터 형태에 맞도록 linear한 모델을 구성해보세요.\n",
    "\n",
    "- MNIST 입력의 크기는 28x28입니다.\n",
    "\n",
    "- 여기서 구현하는 linear 모델은 입력이 1차원이기 때문에 입력 차원을 맞춰보세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6558, -0.9865, -0.3268,  ...,  1.3842, -0.4537,  2.0292],\n",
       "        [-0.4716,  0.4212,  0.8715,  ...,  0.6578,  0.1918, -0.0359],\n",
       "        [ 0.8237, -0.7472, -0.8979,  ..., -0.2953,  0.3836,  0.6029],\n",
       "        ...,\n",
       "        [-0.8371,  0.8613,  0.5890,  ...,  0.3800,  0.6788, -0.5509],\n",
       "        [-0.5659, -0.3064, -0.8841,  ..., -0.2912,  0.2062, -1.0937],\n",
       "        [ 0.6580,  0.0699,  1.1987,  ...,  1.0337, -0.7570, -0.0434]],\n",
       "       requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "linear = torch.nn.Linear(784, 10, bias = True).to(device)\n",
    "torch.nn.init.normal_(linear.weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d451012a",
   "metadata": {},
   "source": [
    "📌Q3. 위에서 구현한 모델을 학습시키기 위해서는 loss 함수와 opitmizer가 필요합니다.\n",
    "아래 제시된 loss 함수와 optimizer를 구현해보세요. Loss 함수와 optimizer는 모델 안\n",
    "의 가중치를 업데이트 할 때 사용됩니다.\n",
    "\n",
    "- 옵티마이저는 SGD, Loss는 Cross Entropy Loss를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f92e6fc6",
   "metadata": {},
   "source": [
    "📌Q4. 3번 문제까지 해결하셨다면, 이제 학습을 위한 준비는 거의 끝났다고 볼 수 있습니다.\n",
    "위 구현 함수들을 이용해 학습 Loop를 구현해보세요.\n",
    "\n",
    "- 위에서 구현한 모델, optimzer, loss fn 등을 이용해 학습을 구현해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec904fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)        \n",
    "        imgs = imgs.view(-1, 28*28)\n",
    "\n",
    "        outputs = linear(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax.to(device)).float().mean()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {: .4f}, Accuracy: {: .2f}%'.format(\n",
    "                epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item()* 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a4cb30a",
   "metadata": {},
   "source": [
    "📌Q5. 학습이 완료되면, 모델이 잘 동작하는지 테스트가 필요합니다. 데이터로드 파트에서\n",
    "준비했던 테스트 데이터를 이용해 테스트를 진행해봅시다. 아래 테스트 코드를 완성해보\n",
    "세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1, 28 * 28)\n",
    "\n",
    "        outputs = linear(imgs)\n",
    "\n",
    "        _, argmax = torch.max(outputs, 1) \n",
    "        total += imgs.size(0)\n",
    "        correct += (labels == argmax).sum().item()\n",
    "    \n",
    "    print('Test accuracy for {} images: {: .2f}%'.format(total, correct / total * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f8929016d30f12a89eab5b5e02a6c1410fc73da4b23b89b4eb7a3bc58137fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
