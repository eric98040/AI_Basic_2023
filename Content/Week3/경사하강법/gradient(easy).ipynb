{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< 미분 >\n",
    "\n",
    "- 미분(differentiation)은 변수의 움직임에 따른 함수값의 변화를 측정하기 위한 도구로 최적화에서 제일 많이 사용하는 기법\n",
    "\n",
    "- 최근에는 미분을 손으로 계산하는 대신 컴퓨터가 계산해줄 수 잇음 : \n",
    "- sympy.diff을 가지고 미분을 컴퓨터로 계산할 수 있음 \n",
    "\n",
    "- 미분은 함수f의 주어진 점(x,f(x))에서의 접선의 기울기를 구함\n",
    "\n",
    "- 한 점에서의 접선의 기울기를 알면 어느 방향으로 움직여야 함수값이 증가하는지/감소하는지 알 수 있음\n",
    "    - delta(y) = delta(x) * f'(x) 이므로 y의 변화량은 x의 변화량 & f'(x)의 부호비교\n",
    "    - 함수값을 증가시키고 싶으면 x에 미분값(f'(x))을 더하고 : x+f'(x)\n",
    "    - 함수값을 감소시키고 싶으면 x에 미분값(f'(x))을 뺀다 : x-f'(x)\n",
    "\n",
    "- 미분값을 더하면 경사상승법(gradient ascent)라 하며, 극댓값의 위치를 구할 때 사용\n",
    "    - 목적함수를 최대화할 때 사용\n",
    "\n",
    "- 미분값을 빼면 경사하강법(gradient descent)라 하며, 극솟값의 위치를 구할 때 사용\n",
    "    - 목적함수를 최소화할 때 사용\n",
    "\n",
    "- 경사상승/경사하강 방법은 극값에 도달하면 움직임을 멈춘다 \n",
    "    - 극값에서는 f'(x) = 0이므로 더 이상 x값이 업데이트가 안 됨\n",
    "    - 즉 목적함수 최적화가 자동으로 끝남\n",
    "\n",
    "\n",
    "< 경사하강법 >\n",
    "\n",
    "- gradient : 미분을 계산하는 함수\n",
    "- init : 시작점, lr : 학습률, eps : 알고리즘 종료조건\n",
    "\n",
    "var = init\n",
    "grad = gradient(var)\n",
    "while (abs(grad) > eps) :\n",
    "    var -= lr * grad\n",
    "    grad = gradient(var)\n",
    " \n",
    "- 컴퓨터로 계산할 때 정확히 0이 되는 것은 불가능하므로 eps보다 작을 때 종료하는 조건이 필요함\n",
    "- lr : 학습률로서 미분을 통해 업데이트하는 속도를 조절함\n",
    "\n",
    "< 편미분 >\n",
    "\n",
    "- 벡터가 입력인 다변수 함수의 경우 편미분(partial differentation)을 사용함\n",
    "- i번째 방향에서의 변화율을 계산할 수 있음 = e_i는 i번째 값만 1이고 나머지는 0인 단위벡터\n",
    "\n",
    "< gradient >\n",
    "\n",
    "- 각 변수별로 편미분을 계산한 gradient vector를 이용하여 경사하강/경사상승법에 사용할 수 있음\n",
    "    - nabla f = [ f'_x1, f'_x2, f'_x3, ..., f'_xd ]\n",
    "    - f를 각 변수별로 미분 (nabla f를 이용하여 변수 x(=x1,...,xd)를 동시에 업데이트 가능)\n",
    "\n",
    "- nabla f = gradient vector는 각 점에서 가장 빨리 증가하는 방향으로 흐르게 됨\n",
    "- -(nabla f) = nabla(-f) =  gradient vector는 각 점에서 가장 빨리 감소하는 방향으로 흐르게 됨\n",
    "\n",
    "< 경사하강법 with 편미분 >\n",
    "\n",
    "- 알고리즘은 동일하나, 벡터는 절댓값 대신 norm을 계산해서 종료조건을 설정함\n",
    "- gradient : 그래디언트 벡터를 계산하는 함수\n",
    "\n",
    "var = init\n",
    "grad = gradient(var)\n",
    "while (norm(grad) > eps) :\n",
    "    var -= lr * grad\n",
    "    grad = gradient(var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\operatorname{Poly}{\\left( 2 x + 2, x, domain=\\mathbb{Z} \\right)}$"
      ],
      "text/plain": [
       "Poly(2*x + 2, x, domain='ZZ')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sym\n",
    "from sympy.abc import x\n",
    "from sympy.abc import y\n",
    "\n",
    "sym.diff((sym.poly(x**2 + 2*x +3)),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수: Poly(x**2 + 2*x + 3, x, domain='ZZ'), 연산횟수: 564, 최소점: (-0.999995090858770, 2.00000000002410)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func(val) :\n",
    "    fun = sym.poly(x**2 + 2*x + 3)\n",
    "    return fun.subs(x,val), fun\n",
    "\n",
    "def func_gradient(fun, val) :\n",
    "    _, function = fun(val)\n",
    "    diff = sym.diff(function,x)\n",
    "    return diff.subs(x,val), diff\n",
    "\n",
    "def gradient_descent(fun, init_point, lr_rate = 1e-2, epsilon = 1e-5):\n",
    "    cnt = 0\n",
    "    val = init_point\n",
    "    diff, _ = func_gradient(fun, init_point)\n",
    "    while np.abs(diff) > epsilon :\n",
    "        val -= lr_rate*diff\n",
    "        diff, _ = func_gradient(fun,val)\n",
    "        cnt+=1\n",
    "        \n",
    "    print(f\"함수: {fun(val)[1]}, 연산횟수: {cnt}, 최소점: ({val}, {fun(val)[0]})\")\n",
    "\n",
    "gradient_descent(fun=func, init_point=np.random.uniform(-2,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수: Poly(x**2 + 2*y**2, x, y, domain='ZZ'), 연산횟수: 571, 최소점: ([ 4.92361826e-06 -8.12341598e-11], 2.42420168039544E-11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "from sympy.abc import x\n",
    "from sympy.abc import y\n",
    "\n",
    "def eval_(fun,val) :\n",
    "    val_x, val_y = val\n",
    "    fun_eval = fun.subs(x,val_x).subs(y,val_y )\n",
    "    return fun_eval\n",
    "\n",
    "def func_multi(val) :\n",
    "    x_,y_ = val\n",
    "    func = sym.poly(x**2 + 2*y**2)\n",
    "    return eval_(func, [x_,y_]), func\n",
    "\n",
    "def func_gradient(fun, val) :\n",
    "    x_, y_ = val\n",
    "    _, function = fun(val)\n",
    "    diff_x = sym.diff(function,x)\n",
    "    diff_y = sym.diff(function,y)\n",
    "    grad_vec = np.array([eval_(diff_x,[x_,y_]), eval_(diff_y,[x_,y_])], dtype=float)\n",
    "    return grad_vec, [diff_x, diff_y]\n",
    "\n",
    "\n",
    "def gradient_descent(fun, init_point, lr_rate = 1e-2, epsilon = 1e-5):\n",
    "    cnt = 0\n",
    "    val = init_point\n",
    "    diff, _ = func_gradient(fun, val)\n",
    "    while np.linalg.norm(diff) > epsilon :\n",
    "        val -= lr_rate*diff\n",
    "        diff, _ = func_gradient(fun,val)\n",
    "        cnt+=1\n",
    "        \n",
    "    print(f\"함수: {fun(val)[1]}, 연산횟수: {cnt}, 최소점: ({val}, {fun(val)[0]})\")\n",
    "\n",
    "pt = [np.random.uniform(-2,2), np.random.uniform(-2,2)]\n",
    "gradient_descent(fun=func_multi, init_point=pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f8929016d30f12a89eab5b5e02a6c1410fc73da4b23b89b4eb7a3bc58137fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
